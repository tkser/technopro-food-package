{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\tkser\\technopro-food-package\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.Eva02Model.train import train as train_eva02\n",
    "\n",
    "from utils.show_graph import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\tkser\\technopro-food-package\\.venv\\Lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "[DEBUG] 2023-09-23 22:55:38 - Using device: cuda(NVIDIA GeForce RTX 3080)\n",
      "[DEBUG] 2023-09-23 22:55:38 - Starting training on cuda at 2023-09-23 22:55:38\n",
      "[DEBUG] 2023-09-23 22:55:38 - Model: Eva\n",
      "[DEBUG] 2023-09-23 22:55:38 - Model parameters:\n",
      "[DEBUG] 2023-09-23 22:55:38 - cls_token: torch.Size([1, 1, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - pos_embed: torch.Size([1, 1025, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - patch_embed.proj.weight: torch.Size([1024, 3, 14, 14])\n",
      "[DEBUG] 2023-09-23 22:55:38 - patch_embed.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.0.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.1.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.2.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.3.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.4.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.5.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.6.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.7.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.8.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.9.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.10.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.11.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.12.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.13.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.14.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.15.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.16.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.17.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.18.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.19.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.20.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.21.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.22.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.norm1.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.norm1.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.attn.q_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.attn.q_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.attn.k_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.attn.v_proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.attn.v_proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.attn.proj.weight: torch.Size([1024, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.attn.proj.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.norm2.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.norm2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.mlp.fc1_g.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.mlp.fc1_g.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.mlp.fc1_x.weight: torch.Size([2730, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.mlp.fc1_x.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.mlp.norm.weight: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.mlp.norm.bias: torch.Size([2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.mlp.fc2.weight: torch.Size([1024, 2730])\n",
      "[DEBUG] 2023-09-23 22:55:38 - blocks.23.mlp.fc2.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - fc_norm.weight: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - fc_norm.bias: torch.Size([1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - head.weight: torch.Size([2, 1024])\n",
      "[DEBUG] 2023-09-23 22:55:38 - head.bias: torch.Size([2])\n",
      "[DEBUG] 2023-09-23 22:55:38 - Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 8e-06\n",
      "    lr: 8e-06\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "[DEBUG] 2023-09-23 22:55:38 - Scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x000002506480AD50>\n",
      "[DEBUG] 2023-09-23 22:55:38 - Loss function: CrossEntropyLoss()\n",
      "[DEBUG] 2023-09-23 22:55:38 - Mixup alpha: 0.0\n",
      "[DEBUG] 2023-09-23 22:55:38 - Epoch: 1 / 25\n",
      "[DEBUG] 2023-09-23 22:55:38 - --------------------------\n",
      "Epoch 1/25: 100%|██████████| 1088/1088 [09:16<00:00,  1.96it/s]\n",
      "[DEBUG] 2023-09-23 23:04:54 - train Loss: 0.6914 AUC: 0.4717\n",
      "Epoch 1/25: 100%|██████████| 1088/1088 [01:27<00:00, 12.45it/s]\n",
      "[DEBUG] 2023-09-23 23:06:22 - val Loss: 0.6915 AUC: 0.5342\n",
      "[DEBUG] 2023-09-23 23:06:23 - New best model saved at d:/repo/tkser/technopro-food-package/src/data/models/Eva02Model/eva_20230923225538_epoch_1_auc_0.5342.pth\n",
      "[DEBUG] 2023-09-23 23:06:23 - Epoch: 2 / 25\n",
      "[DEBUG] 2023-09-23 23:06:23 - --------------------------\n",
      "Epoch 2/25: 100%|██████████| 1088/1088 [09:08<00:00,  1.98it/s]\n",
      "[DEBUG] 2023-09-23 23:15:32 - train Loss: 0.6916 AUC: 0.4890\n",
      "Epoch 2/25: 100%|██████████| 1088/1088 [01:24<00:00, 12.84it/s]\n",
      "[DEBUG] 2023-09-23 23:16:57 - val Loss: 0.6941 AUC: 0.6213\n",
      "[DEBUG] 2023-09-23 23:17:02 - New best model saved at d:/repo/tkser/technopro-food-package/src/data/models/Eva02Model/eva_20230923225538_epoch_2_auc_0.6213.pth\n",
      "[DEBUG] 2023-09-23 23:17:02 - Epoch: 3 / 25\n",
      "[DEBUG] 2023-09-23 23:17:02 - --------------------------\n",
      "Epoch 3/25: 100%|██████████| 1088/1088 [09:03<00:00,  2.00it/s]\n",
      "[DEBUG] 2023-09-23 23:26:06 - train Loss: 0.6895 AUC: 0.5200\n",
      "Epoch 3/25: 100%|██████████| 1088/1088 [01:24<00:00, 12.85it/s]\n",
      "[DEBUG] 2023-09-23 23:27:31 - val Loss: 0.6932 AUC: 0.6417\n",
      "[DEBUG] 2023-09-23 23:27:32 - New best model saved at d:/repo/tkser/technopro-food-package/src/data/models/Eva02Model/eva_20230923225538_epoch_3_auc_0.6417.pth\n",
      "[DEBUG] 2023-09-23 23:27:32 - Epoch: 4 / 25\n",
      "[DEBUG] 2023-09-23 23:27:32 - --------------------------\n",
      "Epoch 4/25: 100%|██████████| 1088/1088 [09:04<00:00,  2.00it/s]\n",
      "[DEBUG] 2023-09-23 23:36:37 - train Loss: 0.6911 AUC: 0.4917\n",
      "Epoch 4/25:  29%|██▊       | 311/1088 [00:24<01:00, 12.94it/s]"
     ]
    }
   ],
   "source": [
    "package_model_path, loss_history, auc_history = train_eva02(\n",
    "    num_epochs=25,\n",
    "    learning_rate=8e-06,\n",
    "    lr_min=1e-07,\n",
    "    batch_size=1,\n",
    "    flozen=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(loss_history, \"Eva02Model Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(auc_history, \"Eva02Model AUC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
